site_name: MLPerf Inference Documentation
repo_url: https://github.com/mlcommons/cm4mlops
theme:
  name: material
  logo: img/logo_v2.svg
  favicon: img/logo_v2.svg
  palette:
    primary: deep purple
    accent: green
  features:
    - content.tabs.link
    - content.code.copy
    - navigation.expand
    - navigation.sections
    - navigation.indexes
    - navigation.instant
    - navigation.tabs
    - navigation.tabs.sticky
    - navigation.top
    - toc.follow
nav:
  - CM Scripts:
    - index.md
    - Python automation:
      - activate-python-venv: Python-automation\activate-python-venv.md
      - get-generic-python-lib: Python-automation\get-generic-python-lib.md
      - get-python3: Python-automation\get-python3.md
      - install-generic-conda-package: Python-automation\install-generic-conda-package.md
      - install-python-src: Python-automation\install-python-src.md
      - install-python-venv: Python-automation\install-python-venv.md
    - MLPerf benchmark support:
      - add-custom-nvidia-system: MLPerf-benchmark-support\add-custom-nvidia-system.md
      - benchmark-any-mlperf-inference-implementation: MLPerf-benchmark-support\benchmark-any-mlperf-inference-implementation.md
      - build-mlperf-inference-server-nvidia: MLPerf-benchmark-support\build-mlperf-inference-server-nvidia.md
      - generate-mlperf-inference-submission: MLPerf-benchmark-support\generate-mlperf-inference-submission.md
      - generate-mlperf-inference-user-conf: MLPerf-benchmark-support\generate-mlperf-inference-user-conf.md
      - generate-mlperf-tiny-report: MLPerf-benchmark-support\generate-mlperf-tiny-report.md
      - generate-mlperf-tiny-submission: MLPerf-benchmark-support\generate-mlperf-tiny-submission.md
      - generate-nvidia-engine: MLPerf-benchmark-support\generate-nvidia-engine.md
      - get-mlperf-inference-intel-scratch-space: MLPerf-benchmark-support\get-mlperf-inference-intel-scratch-space.md
      - get-mlperf-inference-loadgen: MLPerf-benchmark-support\get-mlperf-inference-loadgen.md
      - get-mlperf-inference-nvidia-common-code: MLPerf-benchmark-support\get-mlperf-inference-nvidia-common-code.md
      - get-mlperf-inference-nvidia-scratch-space: MLPerf-benchmark-support\get-mlperf-inference-nvidia-scratch-space.md
      - get-mlperf-inference-results: MLPerf-benchmark-support\get-mlperf-inference-results.md
      - get-mlperf-inference-results-dir: MLPerf-benchmark-support\get-mlperf-inference-results-dir.md
      - get-mlperf-inference-src: MLPerf-benchmark-support\get-mlperf-inference-src.md
      - get-mlperf-inference-submission-dir: MLPerf-benchmark-support\get-mlperf-inference-submission-dir.md
      - get-mlperf-inference-sut-configs: MLPerf-benchmark-support\get-mlperf-inference-sut-configs.md
      - get-mlperf-inference-sut-description: MLPerf-benchmark-support\get-mlperf-inference-sut-description.md
      - get-mlperf-logging: MLPerf-benchmark-support\get-mlperf-logging.md
      - get-mlperf-power-dev: MLPerf-benchmark-support\get-mlperf-power-dev.md
      - get-mlperf-tiny-eembc-energy-runner-src: MLPerf-benchmark-support\get-mlperf-tiny-eembc-energy-runner-src.md
      - get-mlperf-tiny-src: MLPerf-benchmark-support\get-mlperf-tiny-src.md
      - get-mlperf-training-nvidia-code: MLPerf-benchmark-support\get-mlperf-training-nvidia-code.md
      - get-mlperf-training-src: MLPerf-benchmark-support\get-mlperf-training-src.md
      - get-nvidia-mitten: MLPerf-benchmark-support\get-nvidia-mitten.md
      - get-spec-ptd: MLPerf-benchmark-support\get-spec-ptd.md
      - import-mlperf-inference-to-experiment: MLPerf-benchmark-support\import-mlperf-inference-to-experiment.md
      - import-mlperf-tiny-to-experiment: MLPerf-benchmark-support\import-mlperf-tiny-to-experiment.md
      - import-mlperf-training-to-experiment: MLPerf-benchmark-support\import-mlperf-training-to-experiment.md
      - install-mlperf-logging-from-src: MLPerf-benchmark-support\install-mlperf-logging-from-src.md
      - prepare-training-data-bert: MLPerf-benchmark-support\prepare-training-data-bert.md
      - prepare-training-data-resnet: MLPerf-benchmark-support\prepare-training-data-resnet.md
      - preprocess-mlperf-inference-submission: MLPerf-benchmark-support\preprocess-mlperf-inference-submission.md
      - process-mlperf-accuracy: MLPerf-benchmark-support\process-mlperf-accuracy.md
      - push-mlperf-inference-results-to-github: MLPerf-benchmark-support\push-mlperf-inference-results-to-github.md
      - run-all-mlperf-models: MLPerf-benchmark-support\run-all-mlperf-models.md
      - run-mlperf-inference-mobilenet-models: MLPerf-benchmark-support\run-mlperf-inference-mobilenet-models.md
      - run-mlperf-inference-submission-checker: MLPerf-benchmark-support\run-mlperf-inference-submission-checker.md
      - run-mlperf-power-client: MLPerf-benchmark-support\run-mlperf-power-client.md
      - run-mlperf-power-server: MLPerf-benchmark-support\run-mlperf-power-server.md
      - run-mlperf-training-submission-checker: MLPerf-benchmark-support\run-mlperf-training-submission-checker.md
      - truncate-mlperf-inference-accuracy-log: MLPerf-benchmark-support\truncate-mlperf-inference-accuracy-log.md
    - Modular AI-ML application pipeline:
      - app-image-classification-onnx-py: Modular-AI-ML-application-pipeline\app-image-classification-onnx-py.md
      - app-image-classification-tf-onnx-cpp: Modular-AI-ML-application-pipeline\app-image-classification-tf-onnx-cpp.md
      - app-image-classification-torch-py: Modular-AI-ML-application-pipeline\app-image-classification-torch-py.md
      - app-image-classification-tvm-onnx-py: Modular-AI-ML-application-pipeline\app-image-classification-tvm-onnx-py.md
      - app-stable-diffusion-onnx-py: Modular-AI-ML-application-pipeline\app-stable-diffusion-onnx-py.md
    - Modular application pipeline:
      - app-image-corner-detection: Modular-application-pipeline\app-image-corner-detection.md
    - Modular MLPerf inference benchmark pipeline:
      - app-loadgen-generic-python: Modular-MLPerf-inference-benchmark-pipeline\app-loadgen-generic-python.md
      - app-mlperf-inference: Modular-MLPerf-inference-benchmark-pipeline\app-mlperf-inference.md
      - app-mlperf-inference-ctuning-cpp-tflite: Modular-MLPerf-inference-benchmark-pipeline\app-mlperf-inference-ctuning-cpp-tflite.md
      - app-mlperf-inference-mlcommons-cpp: Modular-MLPerf-inference-benchmark-pipeline\app-mlperf-inference-mlcommons-cpp.md
      - app-mlperf-inference-mlcommons-python: Modular-MLPerf-inference-benchmark-pipeline\app-mlperf-inference-mlcommons-python.md
      - benchmark-program-mlperf: Modular-MLPerf-inference-benchmark-pipeline\benchmark-program-mlperf.md
      - run-mlperf-inference-app: Modular-MLPerf-inference-benchmark-pipeline\run-mlperf-inference-app.md
    - Modular MLPerf benchmarks:
      - app-mlperf-inference-dummy: Modular-MLPerf-benchmarks\app-mlperf-inference-dummy.md
      - app-mlperf-inference-intel: Modular-MLPerf-benchmarks\app-mlperf-inference-intel.md
      - app-mlperf-inference-qualcomm: Modular-MLPerf-benchmarks\app-mlperf-inference-qualcomm.md
    - Reproduce MLPerf benchmarks:
      - app-mlperf-inference-nvidia: Reproduce-MLPerf-benchmarks\app-mlperf-inference-nvidia.md
      - reproduce-mlperf-octoml-tinyml-results: Reproduce-MLPerf-benchmarks\reproduce-mlperf-octoml-tinyml-results.md
      - reproduce-mlperf-training-nvidia: Reproduce-MLPerf-benchmarks\reproduce-mlperf-training-nvidia.md
      - wrapper-reproduce-octoml-tinyml-submission: Reproduce-MLPerf-benchmarks\wrapper-reproduce-octoml-tinyml-submission.md
    - Modular MLPerf training benchmark pipeline:
      - app-mlperf-training-nvidia: Modular-MLPerf-training-benchmark-pipeline\app-mlperf-training-nvidia.md
      - app-mlperf-training-reference: Modular-MLPerf-training-benchmark-pipeline\app-mlperf-training-reference.md
    - DevOps automation:
      - benchmark-program: DevOps-automation\benchmark-program.md
      - compile-program: DevOps-automation\compile-program.md
      - convert-csv-to-md: DevOps-automation\convert-csv-to-md.md
      - copy-to-clipboard: DevOps-automation\copy-to-clipboard.md
      - create-conda-env: DevOps-automation\create-conda-env.md
      - create-patch: DevOps-automation\create-patch.md
      - detect-sudo: DevOps-automation\detect-sudo.md
      - download-and-extract: DevOps-automation\download-and-extract.md
      - download-file: DevOps-automation\download-file.md
      - download-torrent: DevOps-automation\download-torrent.md
      - extract-file: DevOps-automation\extract-file.md
      - fail: DevOps-automation\fail.md
      - get-conda: DevOps-automation\get-conda.md
      - get-git-repo: DevOps-automation\get-git-repo.md
      - get-github-cli: DevOps-automation\get-github-cli.md
      - pull-git-repo: DevOps-automation\pull-git-repo.md
      - push-csv-to-spreadsheet: DevOps-automation\push-csv-to-spreadsheet.md
      - set-device-settings-qaic: DevOps-automation\set-device-settings-qaic.md
      - set-echo-off-win: DevOps-automation\set-echo-off-win.md
      - set-performance-mode: DevOps-automation\set-performance-mode.md
      - set-sqlite-dir: DevOps-automation\set-sqlite-dir.md
      - tar-my-folder: DevOps-automation\tar-my-folder.md
    - Docker automation:
      - build-docker-image: Docker-automation\build-docker-image.md
      - build-dockerfile: Docker-automation\build-dockerfile.md
      - prune-docker: Docker-automation\prune-docker.md
      - run-docker-container: Docker-automation\run-docker-container.md
    - AI-ML optimization:
      - calibrate-model-for.qaic: AI-ML-optimization\calibrate-model-for.qaic.md
      - compile-model-for.qaic: AI-ML-optimization\compile-model-for.qaic.md
      - prune-bert-models: AI-ML-optimization\prune-bert-models.md
    - AI-ML models:
      - convert-ml-model-huggingface-to-onnx: AI-ML-models\convert-ml-model-huggingface-to-onnx.md
      - get-bert-squad-vocab: AI-ML-models\get-bert-squad-vocab.md
      - get-dlrm: AI-ML-models\get-dlrm.md
      - get-ml-model-3d-unet-kits19: AI-ML-models\get-ml-model-3d-unet-kits19.md
      - get-ml-model-bert-base-squad: AI-ML-models\get-ml-model-bert-base-squad.md
      - get-ml-model-bert-large-squad: AI-ML-models\get-ml-model-bert-large-squad.md
      - get-ml-model-dlrm-terabyte: AI-ML-models\get-ml-model-dlrm-terabyte.md
      - get-ml-model-efficientnet-lite: AI-ML-models\get-ml-model-efficientnet-lite.md
      - get-ml-model-gptj: AI-ML-models\get-ml-model-gptj.md
      - get-ml-model-huggingface-zoo: AI-ML-models\get-ml-model-huggingface-zoo.md
      - get-ml-model-llama2: AI-ML-models\get-ml-model-llama2.md
      - get-ml-model-mobilenet: AI-ML-models\get-ml-model-mobilenet.md
      - get-ml-model-neuralmagic-zoo: AI-ML-models\get-ml-model-neuralmagic-zoo.md
      - get-ml-model-resnet50: AI-ML-models\get-ml-model-resnet50.md
      - get-ml-model-retinanet: AI-ML-models\get-ml-model-retinanet.md
      - get-ml-model-retinanet-nvidia: AI-ML-models\get-ml-model-retinanet-nvidia.md
      - get-ml-model-rnnt: AI-ML-models\get-ml-model-rnnt.md
      - get-ml-model-stable-diffusion: AI-ML-models\get-ml-model-stable-diffusion.md
      - get-ml-model-tiny-resnet: AI-ML-models\get-ml-model-tiny-resnet.md
      - get-ml-model-using-imagenet-from-model-zoo: AI-ML-models\get-ml-model-using-imagenet-from-model-zoo.md
      - get-tvm-model: AI-ML-models\get-tvm-model.md
    - CM automation:
      - create-custom-cache-entry: CM-automation\create-custom-cache-entry.md
    - TinyML automation:
      - create-fpgaconvnet-app-tinyml: TinyML-automation\create-fpgaconvnet-app-tinyml.md
      - create-fpgaconvnet-config-tinyml: TinyML-automation\create-fpgaconvnet-config-tinyml.md
      - flash-tinyml-binary: TinyML-automation\flash-tinyml-binary.md
      - get-microtvm: TinyML-automation\get-microtvm.md
      - get-zephyr: TinyML-automation\get-zephyr.md
      - get-zephyr-sdk: TinyML-automation\get-zephyr-sdk.md
    - Cloud automation:
      - destroy-terraform: Cloud-automation\destroy-terraform.md
      - get-aws-cli: Cloud-automation\get-aws-cli.md
      - get-terraform: Cloud-automation\get-terraform.md
      - install-aws-cli: Cloud-automation\install-aws-cli.md
      - install-terraform-from-src: Cloud-automation\install-terraform-from-src.md
      - run-terraform: Cloud-automation\run-terraform.md
    - Platform information:
      - detect-cpu: Platform-information\detect-cpu.md
      - detect-os: Platform-information\detect-os.md
    - Detection or installation of tools and artifacts:
      - get-android-sdk: Detection-or-installation-of-tools-and-artifacts\get-android-sdk.md
      - get-aria2: Detection-or-installation-of-tools-and-artifacts\get-aria2.md
      - get-bazel: Detection-or-installation-of-tools-and-artifacts\get-bazel.md
      - get-blis: Detection-or-installation-of-tools-and-artifacts\get-blis.md
      - get-brew: Detection-or-installation-of-tools-and-artifacts\get-brew.md
      - get-cmake: Detection-or-installation-of-tools-and-artifacts\get-cmake.md
      - get-cmsis_5: Detection-or-installation-of-tools-and-artifacts\get-cmsis_5.md
      - get-docker: Detection-or-installation-of-tools-and-artifacts\get-docker.md
      - get-generic-sys-util: Detection-or-installation-of-tools-and-artifacts\get-generic-sys-util.md
      - get-google-test: Detection-or-installation-of-tools-and-artifacts\get-google-test.md
      - get-java: Detection-or-installation-of-tools-and-artifacts\get-java.md
      - get-javac: Detection-or-installation-of-tools-and-artifacts\get-javac.md
      - get-lib-armnn: Detection-or-installation-of-tools-and-artifacts\get-lib-armnn.md
      - get-lib-dnnl: Detection-or-installation-of-tools-and-artifacts\get-lib-dnnl.md
      - get-lib-protobuf: Detection-or-installation-of-tools-and-artifacts\get-lib-protobuf.md
      - get-lib-qaic-api: Detection-or-installation-of-tools-and-artifacts\get-lib-qaic-api.md
      - get-nvidia-docker: Detection-or-installation-of-tools-and-artifacts\get-nvidia-docker.md
      - get-openssl: Detection-or-installation-of-tools-and-artifacts\get-openssl.md
      - get-rclone: Detection-or-installation-of-tools-and-artifacts\get-rclone.md
      - get-sys-utils-cm: Detection-or-installation-of-tools-and-artifacts\get-sys-utils-cm.md
      - get-sys-utils-min: Detection-or-installation-of-tools-and-artifacts\get-sys-utils-min.md
      - get-xilinx-sdk: Detection-or-installation-of-tools-and-artifacts\get-xilinx-sdk.md
      - get-zendnn: Detection-or-installation-of-tools-and-artifacts\get-zendnn.md
      - install-bazel: Detection-or-installation-of-tools-and-artifacts\install-bazel.md
      - install-cmake-prebuilt: Detection-or-installation-of-tools-and-artifacts\install-cmake-prebuilt.md
      - install-gflags: Detection-or-installation-of-tools-and-artifacts\install-gflags.md
      - install-github-cli: Detection-or-installation-of-tools-and-artifacts\install-github-cli.md
      - install-numactl-from-src: Detection-or-installation-of-tools-and-artifacts\install-numactl-from-src.md
      - install-openssl: Detection-or-installation-of-tools-and-artifacts\install-openssl.md
    - Compiler automation:
      - get-aocl: Compiler-automation\get-aocl.md
      - get-cl: Compiler-automation\get-cl.md
      - get-compiler-flags: Compiler-automation\get-compiler-flags.md
      - get-compiler-rust: Compiler-automation\get-compiler-rust.md
      - get-gcc: Compiler-automation\get-gcc.md
      - get-go: Compiler-automation\get-go.md
      - get-llvm: Compiler-automation\get-llvm.md
      - install-gcc-src: Compiler-automation\install-gcc-src.md
      - install-ipex-from-src: Compiler-automation\install-ipex-from-src.md
      - install-llvm-prebuilt: Compiler-automation\install-llvm-prebuilt.md
      - install-llvm-src: Compiler-automation\install-llvm-src.md
      - install-onednn-from-src: Compiler-automation\install-onednn-from-src.md
      - install-onnxruntime-from-src: Compiler-automation\install-onnxruntime-from-src.md
      - install-pytorch-from-src: Compiler-automation\install-pytorch-from-src.md
      - install-pytorch-kineto-from-src: Compiler-automation\install-pytorch-kineto-from-src.md
      - install-torchvision-from-src: Compiler-automation\install-torchvision-from-src.md
      - install-tpp-pytorch-extension: Compiler-automation\install-tpp-pytorch-extension.md
      - install-transformers-from-src: Compiler-automation\install-transformers-from-src.md
    - CM Interface:
      - get-cache-dir: CM-Interface\get-cache-dir.md
    - Legacy CK support:
      - get-ck: Legacy-CK-support\get-ck.md
      - get-ck-repo-mlops: Legacy-CK-support\get-ck-repo-mlops.md
    - AI-ML datasets:
      - get-croissant: AI-ML-datasets\get-croissant.md
      - get-dataset-cifar10: AI-ML-datasets\get-dataset-cifar10.md
      - get-dataset-cnndm: AI-ML-datasets\get-dataset-cnndm.md
      - get-dataset-coco: AI-ML-datasets\get-dataset-coco.md
      - get-dataset-coco2014: AI-ML-datasets\get-dataset-coco2014.md
      - get-dataset-criteo: AI-ML-datasets\get-dataset-criteo.md
      - get-dataset-imagenet-aux: AI-ML-datasets\get-dataset-imagenet-aux.md
      - get-dataset-imagenet-calibration: AI-ML-datasets\get-dataset-imagenet-calibration.md
      - get-dataset-imagenet-helper: AI-ML-datasets\get-dataset-imagenet-helper.md
      - get-dataset-imagenet-train: AI-ML-datasets\get-dataset-imagenet-train.md
      - get-dataset-imagenet-val: AI-ML-datasets\get-dataset-imagenet-val.md
      - get-dataset-kits19: AI-ML-datasets\get-dataset-kits19.md
      - get-dataset-librispeech: AI-ML-datasets\get-dataset-librispeech.md
      - get-dataset-openimages: AI-ML-datasets\get-dataset-openimages.md
      - get-dataset-openimages-annotations: AI-ML-datasets\get-dataset-openimages-annotations.md
      - get-dataset-openimages-calibration: AI-ML-datasets\get-dataset-openimages-calibration.md
      - get-dataset-openorca: AI-ML-datasets\get-dataset-openorca.md
      - get-dataset-squad: AI-ML-datasets\get-dataset-squad.md
      - get-dataset-squad-vocab: AI-ML-datasets\get-dataset-squad-vocab.md
      - get-preprocessed-dataset-criteo: AI-ML-datasets\get-preprocessed-dataset-criteo.md
      - get-preprocessed-dataset-generic: AI-ML-datasets\get-preprocessed-dataset-generic.md
      - get-preprocessed-dataset-imagenet: AI-ML-datasets\get-preprocessed-dataset-imagenet.md
      - get-preprocessed-dataset-kits19: AI-ML-datasets\get-preprocessed-dataset-kits19.md
      - get-preprocessed-dataset-librispeech: AI-ML-datasets\get-preprocessed-dataset-librispeech.md
      - get-preprocessed-dataset-openimages: AI-ML-datasets\get-preprocessed-dataset-openimages.md
      - get-preprocessed-dataset-openorca: AI-ML-datasets\get-preprocessed-dataset-openorca.md
      - get-preprocessed-dataset-squad: AI-ML-datasets\get-preprocessed-dataset-squad.md
    - CUDA automation:
      - get-cuda: CUDA-automation\get-cuda.md
      - get-cuda-devices: CUDA-automation\get-cuda-devices.md
      - get-cudnn: CUDA-automation\get-cudnn.md
      - get-tensorrt: CUDA-automation\get-tensorrt.md
      - install-cuda-package-manager: CUDA-automation\install-cuda-package-manager.md
      - install-cuda-prebuilt: CUDA-automation\install-cuda-prebuilt.md
    - AI-ML frameworks:
      - get-google-saxml: AI-ML-frameworks\get-google-saxml.md
      - get-onnxruntime-prebuilt: AI-ML-frameworks\get-onnxruntime-prebuilt.md
      - get-qaic-apps-sdk: AI-ML-frameworks\get-qaic-apps-sdk.md
      - get-qaic-platform-sdk: AI-ML-frameworks\get-qaic-platform-sdk.md
      - get-qaic-software-kit: AI-ML-frameworks\get-qaic-software-kit.md
      - get-rocm: AI-ML-frameworks\get-rocm.md
      - get-tvm: AI-ML-frameworks\get-tvm.md
      - install-qaic-compute-sdk-from-src: AI-ML-frameworks\install-qaic-compute-sdk-from-src.md
      - install-rocm: AI-ML-frameworks\install-rocm.md
      - install-tensorflow-for-c: AI-ML-frameworks\install-tensorflow-for-c.md
      - install-tensorflow-from-src: AI-ML-frameworks\install-tensorflow-from-src.md
      - install-tflite-from-src: AI-ML-frameworks\install-tflite-from-src.md
    - Reproducibility and artifact evaluation:
      - get-ipol-src: Reproducibility-and-artifact-evaluation\get-ipol-src.md
      - process-ae-users: Reproducibility-and-artifact-evaluation\process-ae-users.md
      - reproduce-ipol-paper-2022-439: Reproducibility-and-artifact-evaluation\reproduce-ipol-paper-2022-439.md
      - reproduce-micro-paper-2023-victima: Reproducibility-and-artifact-evaluation\reproduce-micro-paper-2023-victima.md
    - GUI:
      - gui: GUI\gui.md
    - Collective benchmarking:
      - launch-benchmark: Collective-benchmarking\launch-benchmark.md
    - Tests:
      - print-any-text: Tests\print-any-text.md
      - print-croissant-desc: Tests\print-croissant-desc.md
      - print-hello-world: Tests\print-hello-world.md
      - print-hello-world-java: Tests\print-hello-world-java.md
      - print-hello-world-javac: Tests\print-hello-world-javac.md
      - print-hello-world-py: Tests\print-hello-world-py.md
      - print-python-version: Tests\print-python-version.md
      - run-python: Tests\run-python.md
      - test-cm-core: Tests\test-cm-core.md
      - test-cm-script-pipeline: Tests\test-cm-script-pipeline.md
      - test-deps-conditions: Tests\test-deps-conditions.md
      - test-deps-conditions2: Tests\test-deps-conditions2.md
      - test-download-and-extract-artifacts: Tests\test-download-and-extract-artifacts.md
      - test-set-sys-user-cm: Tests\test-set-sys-user-cm.md
      - upgrade-python-pip: Tests\upgrade-python-pip.md
    - Dashboard automation:
      - publish-results-to-dashboard: Dashboard-automation\publish-results-to-dashboard.md
    - Remote automation:
      - remote-run-commands: Remote-automation\remote-run-commands.md
    - CM interface prototyping:
      - test-debug: CM-interface-prototyping\test-debug.md
      - test-mlperf-inference-retinanet: CM-interface-prototyping\test-mlperf-inference-retinanet.md

markdown_extensions:
  - pymdownx.tasklist:
      custom_checkbox: true
  - pymdownx.details
  - admonition
  - attr_list
  - def_list
  - footnotes
  - pymdownx.superfences:
      custom_fences:
        - name: mermaid
          class: mermaid
          format: !!python/name:pymdownx.superfences.fence_code_format
  - pymdownx.tabbed:
      alternate_style: true
plugins:
  - search
  - macros
