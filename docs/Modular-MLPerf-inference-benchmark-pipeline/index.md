The Modular MLPerf inference benchmark pipeline category contains the following scripts:

- [app-loadgen-generic-python](https://github.com/anandhu-eng/cm4mlops/tree/mlperf-inference/script/app-loadgen-generic-python/README.md)
- [app-mlperf-inference](https://github.com/anandhu-eng/cm4mlops/tree/mlperf-inference/script/app-mlperf-inference/README.md)
- [app-mlperf-inference-ctuning-cpp-tflite](https://github.com/anandhu-eng/cm4mlops/tree/mlperf-inference/script/app-mlperf-inference-ctuning-cpp-tflite/README.md)
- [app-mlperf-inference-mlcommons-cpp](https://github.com/anandhu-eng/cm4mlops/tree/mlperf-inference/script/app-mlperf-inference-mlcommons-cpp/README.md)
- [app-mlperf-inference-mlcommons-python](https://github.com/anandhu-eng/cm4mlops/tree/mlperf-inference/script/app-mlperf-inference-mlcommons-python/README.md)
- [benchmark-program-mlperf](https://github.com/anandhu-eng/cm4mlops/tree/mlperf-inference/script/benchmark-program-mlperf/README.md)
- [run-mlperf-inference-app](https://github.com/anandhu-eng/cm4mlops/tree/mlperf-inference/script/run-mlperf-inference-app/README.md)
