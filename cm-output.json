{
  "tmp_test_value": 10.0,
  "info": {
    "host_os_name": "posix",
    "host_system": "Linux",
    "host_os_release": "6.8.0-35-generic",
    "host_machine": "x86_64",
    "host_architecture": [
      "64bit",
      "ELF"
    ],
    "host_python_version": "3.12.3",
    "host_sys_version": "3.12.3 (main, Apr 10 2024, 05:33:47) [GCC 13.2.0]",
    "run_uid": "46ebb821c62d4dfe",
    "run_iso_datetime": "2024-06-25T00:26:28.986382"
  },
  "input": {
    "action": "run",
    "automation": "script",
    "tags": "run-mlperf,inference,_find-performance,_full",
    "model": "mixtral-8x7b-99",
    "implementation": "reference",
    "framework": "pytorch",
    "category": "edge",
    "scenario": "Offline",
    "execution_mode": "test",
    "device": "cuda",
    "test_query_count": "100",
    "adr": {
      "cuda": {
        "version": "12.4.1"
      }
    },
    "quiet": true,
    "repro": true,
    "cmd": [
      "--tags=run-mlperf,inference,_find-performance,_full",
      "--model=mixtral-8x7b-99",
      "--implementation=reference",
      "--framework=pytorch",
      "--category=edge",
      "--scenario=Offline",
      "--execution_mode=test",
      "--device=cuda",
      "--test_query_count=100",
      "--adr.cuda.version=12.4.1",
      "--quiet",
      "--repro"
    ],
    "out": "con",
    "parsed_automation": [
      [
        "script",
        "5b4e0237da074764"
      ]
    ]
  }
}