{
  "CM_HW_META": {
    "accelerator_frequency": "2520.000000 MHz",
    "accelerator_host_interconnect": "N/A",
    "accelerator_interconnect": "N/A",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "23.64288330078125 GB",
    "accelerator_memory_configuration": "N/A",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": "1",
    "cooling": "air",
    "division": "open",
    "framework": "pytorch2.2",
    "host_memory_capacity": "134G",
    "host_memory_configuration": "undefined",
    "host_network_card_count": "1",
    "host_networking": "Gig Ethernet",
    "host_networking_topology": "N/A",
    "host_processor_caches": "L1d cache: 896 KiB (24 instances), L1i cache: 1.3 MiB (24 instances), L2 cache: 32 MiB (12 instances), L3 cache: 36 MiB (1 instance)",
    "host_processor_core_count": "24",
    "host_processor_frequency": "5800.0000",
    "host_processor_interconnect": "",
    "host_processor_model_name": "13th Gen Intel(R) Core(TM) i9-13900K",
    "host_processors_per_node": "1",
    "host_storage_capacity": "6.4T",
    "host_storage_type": "SSD",
    "hw_notes": "",
    "number_of_nodes": "1",
    "operating_system": "Ubuntu 24.04 (linux-6.8.0-31-generic-glibc2.39)",
    "other_software_stack": "Python: 3.12.3, LLVM-15.0.6",
    "status": "available",
    "submitter": "CTuning",
    "sw_notes": "",
    "system_name": "intel_spr_i9 (auto detected)",
    "system_type": "edge",
    "system_type_detail": "edge server"
  },
  "CM_SUT_CONFIG": {
    "intel_spr_i9-reference-gpu-pytorch-v2.3.0-network_sut": {
      "3d-unet-99": {
        "Offline": {
          "target_qps": 1.0
        },
        "Server": {
          "target_qps": 1.0
        },
        "SingleStream": {
          "target_latency": 500
        }
      },
      "3d-unet-99.9": {
        "Offline": {
          "target_qps": 1.0
        },
        "Server": {
          "target_qps": 1.0
        },
        "SingleStream": {
          "target_latency": 500
        }
      },
      "bert-99": {
        "Offline": {
          "target_qps": 1
        },
        "Server": {
          "target_qps": 1.0
        },
        "SingleStream": {
          "target_latency": 1
        }
      },
      "bert-99.9": {
        "Offline": {
          "target_qps": 1.0
        },
        "Server": {
          "target_qps": 1.0
        }
      },
      "gpt-j": {
        "Offline": {
          "target_qps": 1.0
        },
        "Server": {
          "target_qps": 1.0
        },
        "SingleStream": {
          "target_latency": 500
        }
      },
      "llama2-70b-99": {
        "Offline": {
          "target_qps": 0.1
        },
        "Server": {
          "target_qps": 0.1
        },
        "SingleStream": {
          "target_latency": 2000
        }
      },
      "llama2-70b-99.9": {
        "Offline": {
          "target_qps": 0.1
        },
        "Server": {
          "target_qps": 0.1
        },
        "SingleStream": {
          "target_latency": 2000
        }
      },
      "resnet50": {
        "MultiStream": {
          "target_latency": 0.1
        },
        "Offline": {
          "target_qps": 1.0
        },
        "Server": {
          "target_qps": 1.0
        },
        "SingleStream": {
          "target_latency": 0.1
        }
      },
      "retinanet": {
        "MultiStream": {
          "target_latency": 1
        },
        "Offline": {
          "target_qps": 1.0
        },
        "Server": {
          "target_qps": 1.0
        },
        "SingleStream": {
          "target_latency": 1
        }
      },
      "sdxl": {
        "Offline": {
          "target_qps": 1.0
        },
        "Server": {
          "target_qps": 1.0
        },
        "SingleStream": {
          "target_latency": 200
        }
      }
    }
  },
  "CM_SUT_CONFIG_NAME": "intel_spr_i9-reference-gpu-pytorch-v2.3.0-network_sut",
  "CM_SUT_CONFIG_PATH": {
    "intel_spr_i9-reference-gpu-pytorch-v2.3.0-network_sut": "/home/anandhu/CM/repos/local/cache/5043351ffa174ecf/configs/intel_spr_i9/reference-implementation/gpu-device/pytorch-framework/framework-version-v2.3.0/network_sut-config.yaml"
  },
  "CM_SUT_META": {
    "accelerator_frequency": "2520.000000 MHz",
    "accelerator_host_interconnect": "N/A",
    "accelerator_interconnect": "N/A",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "23.64288330078125 GB",
    "accelerator_memory_configuration": "N/A",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": "1",
    "cooling": "air",
    "division": "open",
    "framework": "pytorch2.2",
    "host_memory_capacity": "134G",
    "host_memory_configuration": "undefined",
    "host_network_card_count": "1",
    "host_networking": "Gig Ethernet",
    "host_networking_topology": "N/A",
    "host_processor_caches": "L1d cache: 896 KiB (24 instances), L1i cache: 1.3 MiB (24 instances), L2 cache: 32 MiB (12 instances), L3 cache: 36 MiB (1 instance)",
    "host_processor_core_count": "24",
    "host_processor_frequency": "5800.0000",
    "host_processor_interconnect": "",
    "host_processor_model_name": "13th Gen Intel(R) Core(TM) i9-13900K",
    "host_processors_per_node": "1",
    "host_storage_capacity": "6.4T",
    "host_storage_type": "SSD",
    "hw_notes": "",
    "number_of_nodes": "1",
    "operating_system": "Ubuntu 24.04 (linux-6.8.0-31-generic-glibc2.39)",
    "other_software_stack": "Python: 3.12.3, LLVM-15.0.6",
    "status": "available",
    "submitter": "CTuning",
    "sw_notes": "",
    "system_name": "intel_spr_i9 (auto detected)",
    "system_type": "edge",
    "system_type_detail": "edge server"
  },
  "RUN": {
    "Offline": {}
  },
  "docker": {},
  "mlperf-inference-implementation": {
    "script_id": "app-mlperf-inference,d775cac873ee4231:reference,bert-99,pytorch,cuda,test,offline"
  },
  "mlperf_inference_run_cmd": "cm run script --tags=generate-run-cmds,inference --model=bert-99 --backend=pytorch --mode=performance --device=cuda --quiet --test_query_count=1000 --network=sut --adr.cuda.version=12.4.1",
  "os_uname_all": "Linux intel-spr-i9 6.8.0-31-generic #31-Ubuntu SMP PREEMPT_DYNAMIC Sat Apr 20 00:40:06 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux",
  "os_uname_machine": "x86_64"
}
